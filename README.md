# IngestÃ£o e Busca SemÃ¢ntica com LangChain e Postgres

Desafio Tecnico - MBA IA Engenharia de Software - FullCycle\
Aluno: FÃ¡bio Celso de Mattos\
Turma: Setembro 2025

---

Objetivos do Desafio:
Sistema de pergunta e resposta baseado em documentos PDF usando LangChain, PostgreSQL com pgVector e Google Gemini.

## ğŸš€ Funcionalidades

- **IngestÃ£o**: LÃª arquivos PDF e salva em banco vetorial PostgreSQL
- **Busca SemÃ¢ntica**: Permite fazer perguntas via CLI sobre o conteÃºdo do PDF
- **Respostas Contextualizadas**: Responde apenas com base no conteÃºdo do documento

## ğŸ› ï¸ Tecnologias

- **Python 3.9+**
- **LangChain** - Framework para aplicaÃ§Ãµes com LLM
- **PostgreSQL + pgVector** - Banco de dados vetorial
- **Google Gemini** - Embeddings e LLM
- **Docker & Docker Compose** - ContainerizaÃ§Ã£o do banco

## ğŸ“‹ PrÃ©-requisitos

1. **Python 3.9+** instalado
2. **Docker e Docker Compose** instalados
   Link como instalar Docker e Doker Compose
   https://www.docker.com/products/docker-desktop/

3. **API Key do Google Gemini**
   <br>OBS: Para gerar a API Key do Google Gemini <br>acesse o site:
   https://aistudio.google.com/app/apikey

## âš™ï¸ ConfiguraÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/fabio-mattos/mba-ia-desafio-ingestao-busca
cd mba-ia-desafio-ingestao-busca
```

### 2. Configure as variÃ¡veis de ambiente

Configure sua API Key no arquivo `.env`:

```env
GOOGLE_API_KEY=[troque_esse_testo_pela_sua_api_key]
GEMINI_EMBEDDING_MODEL=models/embedding-001
PGVECTOR_URL=postgresql+psycopg://postgres:postgres@localhost:5432/rag
GEMINI_VECTOR_COLLECTION=default_gemini_collection
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
pip install python-dotenv
pip install langchain langchain-community langchain-core
```

## ğŸš€ ExecuÃ§Ã£o

### 1. Subir o banco de dados PostgreSQL

```bash
docker compose up -d
```

Aguarde alguns segundos para o banco inicializar completamente.

### 2. Executar a ingestÃ£o do PDF

```bash
python src/ingest.py
```

Este comando irÃ¡:

- Carregar o arquivo `document.pdf`
- Dividir em chunks de 1000 caracteres (overlap de 150)
- Gerar embeddings usando Google Gemini
- Salvar no banco vetorial PostgreSQL

### 3. Iniciar o chat

```bash
python src/chat.py
```

## ğŸ’¬ Exemplo de Uso

```
ğŸ¤– Chat com Documentos - Sistema RAG
==================================================

FaÃ§a sua pergunta: Qual o faturamento da Empresa SuperTechIABrazil?
PERGUNTA: Qual o faturamento da Empresa SuperTechIABrazil?
==================================================
RESPOSTA: O faturamento foi de 10 milhÃµes de reais.
==================================================

FaÃ§a sua pergunta: Quantos clientes temos em 2024?
PERGUNTA: Quantos clientes temos em 2024?
==================================================
RESPOSTA: NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta.
==================================================
```

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ docker-compose.yml     # ConfiguraÃ§Ã£o do PostgreSQL + pgVector
â”œâ”€â”€ requirements.txt       # DependÃªncias Python
â”œâ”€â”€ .env                  # VariÃ¡veis de ambiente
â”œâ”€â”€ document.pdf          # PDF para ingestÃ£o
â”œâ”€â”€ README.md             # Este arquivo
â””â”€â”€ src/
    â”œâ”€â”€ ingest.py         # Script de ingestÃ£o do PDF
    â”œâ”€â”€ search.py         # LÃ³gica de busca semÃ¢ntica
    â””â”€â”€ chat.py           # Interface CLI para chat
```

## ğŸ”§ ParÃ¢metros de ConfiguraÃ§Ã£o

### IngestÃ£o

- **Chunk size**: 1000 caracteres
- **Chunk overlap**: 150 caracteres
- **Embedding model**: `models/embedding-001` (Google Gemini)

### Busca

- **NÃºmero de documentos recuperados**: 10 (k=10)
- **LLM**: `gemini-1.5-flash`
- **Temperature**: 0 (respostas determinÃ­sticas)
